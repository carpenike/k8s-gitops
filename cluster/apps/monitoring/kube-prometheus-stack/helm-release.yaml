---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  interval: 5m
  chart:
    spec:
      # renovate: registryUrl=https://prometheus-community.github.io/helm-charts
      chart: kube-prometheus-stack
      version: 16.1.0
      sourceRef:
        kind: HelmRepository
        name: prometheus-community-charts
        namespace: flux-system
      interval: 5m
  values:
    # defaultRules:
    #   rules:
    #     kubeApiserverAvailability: false
    #     kubeApiserver: false
    server:
      resources:
        requests:
          memory: 1500Mi
          cpu: 25m
        limits:
          memory: 2000Mi
    prometheusOperator:
      createCustomResource: false
      prometheusConfigReloaderImage:
        repository: quay.io/prometheus-operator/prometheus-config-reloader
        tag: v0.48.0
      configmapReloadImage:
        repository: docker.io/jimmidyson/configmap-reload
        tag: v0.5.0
    alertmanager:
      alertmanagerSpec:
        storage:
          volumeClaimTemplate:
            spec:
              storageClassName: rook-ceph-block
              resources:
                requests:
                  storage: 10Gi
        tolerations:
        - key: "arm"
          operator: "Exists"
      ingress:
        enabled: true
        pathType: Prefix
        ingressClassName: "nginx"
        annotations:
          kubernetes.io/tls-acme: "true"
          cert-manager.io/cluster-issuer: letsencrypt-production
          nginx.ingress.kubernetes.io/auth-url: "https://auth.holthome.net/oauth2/auth"
          nginx.ingress.kubernetes.io/auth-signin: "https://auth.holthome.net/oauth2/start?rd=$escaped_request_uri"
        hosts:
        - prom-alert.holthome.net
        tls:
        - hosts:
          - prom-alert.holthome.net
          secretName: alertmanager-cert
      config:
        global:
          resolve_timeout: 5m
        route:
          # group_by: ['alertname', 'job']
          # group_wait: 30s
          # group_interval: 5m
          # repeat_interval: 6h
          receiver: 'alertmanager-bot'
          # routes:
          #   - match:
          #       alertname: Watchdog
          #     receiver: 'null'
          routes:
          - match:
              alertname: Watchdog
            receiver: 'null'
          - receiver: 'pagerduty'
            match:
              severity: critical
            continue: true
        inhibit_rules:
        - source_match:
            severity: 'critical'
          target_match:
            severity: 'warning'
          # Apply inhibition if the alertname is the same.
          equal: ['alertname', 'namespace']
        templates: ["*.tmpl"]
      templateFiles:
        pagerduty-custom.tmpl: |-
          {{- define "pagerduty.custom.description" -}}[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ if ne .CommonAnnotations.summary ""}}{{ .CommonAnnotations.summary }} {{ else if ne .CommonAnnotations.message ""}}{{ .CommonAnnotations.message }} {{ else if ne .CommonAnnotations.description ""}}{{ .CommonAnnotations.description }} {{ else }}{{ .CommonLabels.alertname }}{{ end }}{{- end -}}
    nodeExporter:
      serviceMonitor:
        relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels:
          - __meta_kubernetes_pod_node_name
          targetLabel: kubernetes_node
    kubelet:
      serviceMonitor:
        metricRelabelings:
        - action: replace
          sourceLabels:
          - node
          targetLabel: instance
    grafana:
      enabled: false
    kubeEtcd:
      enabled: false
    kubeControllerManager:
      enabled: false
      # endpoints:
      # - 10.20.10.16
    kubeScheduler:
      enabled: false
      # endpoints:
      # - 10.20.10.16
    kubeProxy:
      enabled: false
    prometheus-node-exporter:
      fullnameOverride: node-exporter
      tolerations:
      - key: "arm"
        operator: "Exists"
      - key: "armhf"
        operator: "Exists"
    prometheus:
      fullnameOverride: prometheus
      ingress:
        enabled: true
        pathType: Prefix
        ingressClassName: "nginx"
        annotations:
          kubernetes.io/tls-acme: "true"
          cert-manager.io/cluster-issuer: letsencrypt-production
          nginx.ingress.kubernetes.io/auth-url: "https://auth.holthome.net/oauth2/auth"
          nginx.ingress.kubernetes.io/auth-signin: "https://auth.holthome.net/oauth2/start?rd=$escaped_request_uri"
        hosts:
        - prom-server.holthome.net
        tls:
        - hosts:
          - prom-server.holthome.net
          secretName: prom-cert
      prometheusSpec:
        # image:
        #   repository: quay.io/prometheus/prometheus
        #   tag: v2.20.0
        replicas: 2
        replicaExternalLabelName: "replica"
        ruleSelector: {}
        ruleNamespaceSelector: {}
        ruleSelectorNilUsesHelmValues: false
        serviceMonitorSelector: {}
        serviceMonitorNamespaceSelector: {}
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelector: {}
        podMonitorNamespaceSelector: {}
        podMonitorSelectorNilUsesHelmValues: false
        retention: 6h
        enableAdminAPI: true
        walCompression: true
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: rook-ceph-block
              resources:
                requests:
                  storage: 10Gi
        thanos:
          image: quay.io/thanos/thanos:v0.20.2
          version: v0.17.2
          objectStorageConfig:
            name: thanos
            key: object-store.yaml
    kube-state-metrics:
      fullnameOverride: kube-state-metrics
  valuesFrom:
  - kind: Secret
    name: "kube-prometheus-stack-helm-values"
    optional: false
